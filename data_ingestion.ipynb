{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?/export=download&id=1wY2FSROsMASbX69kYBzn5_Y1DlcsJZpv\n",
      "From (redirected): https://drive.google.com/uc?/export=download&id=1wY2FSROsMASbX69kYBzn5_Y1DlcsJZpv&confirm=t&uuid=5e9b8cca-fd47-4dca-a78b-7d665f50be35\n",
      "To: e:\\datascience\\Chest-CT-Scan-data.zip\n",
      "100%|██████████| 1.63G/1.63G [07:19<00:00, 3.70MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chest-CT-Scan-data.zip'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = \"https://drive.google.com/file/d/1wY2FSROsMASbX69kYBzn5_Y1DlcsJZpv/view?usp=drive_link\"\n",
    "\n",
    "file_id = url.split(\"/\")[-2]\n",
    "file_id\n",
    "\n",
    "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "gdown.download(prefix+file_id, \"Chest-CT-Scan-data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"Chest-CT-Scan-data.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 directories and 0 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'.\n",
      "There are 4 directories and 0 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'.\n",
      "There are 0 directories and 3709 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\Cyst'.\n",
      "There are 0 directories and 5077 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\Normal'.\n",
      "There are 0 directories and 1377 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\Stone'.\n",
      "There are 0 directories and 2283 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\Tumor'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_train_test_folders(root_dir, classes, test_size=0.2, random_state=42):\n",
    "    # Create train and test directories\n",
    "    train_dir = os.path.join(root_dir, \"train\")\n",
    "    test_dir = os.path.join(root_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in classes:\n",
    "        # Get the list of images for the current class\n",
    "        class_images = os.listdir(os.path.join(root_dir, root_dir, class_name))  # Adjusted path\n",
    "\n",
    "        # Split the images into train and test sets\n",
    "        train_images, test_images = train_test_split(class_images, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Create directories for the current class in train and test folders\n",
    "        train_class_dir = os.path.join(train_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        # Copy images to the corresponding train and test class directories\n",
    "        for image in train_images:\n",
    "            source_path = os.path.join(root_dir, root_dir, class_name, image)  # Adjusted path\n",
    "            destination_path = os.path.join(train_class_dir, image)\n",
    "            shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "        for image in test_images:\n",
    "            source_path = os.path.join(root_dir, root_dir, class_name, image)  # Adjusted path\n",
    "            destination_path = os.path.join(test_class_dir, image)\n",
    "            shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# Example usage:\n",
    "root_directory = 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'\n",
    "class_names = ['Cyst', 'Normal', 'Stone', 'Tumor']\n",
    "\n",
    "create_train_test_folders(root_directory, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/train/\"\n",
    "test_dir = \"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:\n",
      "Found 9955 images belonging to 4 classes.\n",
      "Testing images:\n",
      "Found 2491 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=IMAGE_SHAPE,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\")\n",
    "\n",
    "print(\"Testing images:\")\n",
    "test_data = train_datagen.flow_from_directory(test_dir,\n",
    "                                              target_size=IMAGE_SHAPE,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              class_mode=\"categorical\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define IMAGE_SHAPE based on the expected input shape of the model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "def create_model(model_url, num_classes=4):\n",
    "    \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
    "    \n",
    "    Args:\n",
    "      model_url (str): A TensorFlow Hub feature extraction URL.\n",
    "      num_classes (int): Number of output neurons in output layer,\n",
    "        should be equal to the number of target classes, default 4.\n",
    "    \n",
    "    Returns:\n",
    "      An uncompiled Keras Sequential model with model_url as a feature\n",
    "      extractor layer and Dense output layer with num_classes outputs.\n",
    "    \"\"\"\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                             trainable=False,  # freeze the underlying patterns\n",
    "                                             name='feature_extraction_layer',\n",
    "                                             input_shape=IMAGE_SHAPE + (3,))  # define the input image shape\n",
    "\n",
    "    # Create our own model\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,  # use the feature extraction layer as the base\n",
    "        layers.Dense(num_classes, activation='softmax', name='output_layer')  # create our own output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model1 = create_model(\"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-classification/versions/4\", num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 309s 978ms/step - loss: 0.5496 - accuracy: 0.8019 - val_loss: 0.3383 - val_accuracy: 0.8892\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 222s 710ms/step - loss: 0.2580 - accuracy: 0.9168 - val_loss: 0.2302 - val_accuracy: 0.9293\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 281s 903ms/step - loss: 0.1958 - accuracy: 0.9413 - val_loss: 0.1916 - val_accuracy: 0.9434\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 305s 976ms/step - loss: 0.1551 - accuracy: 0.9551 - val_loss: 0.1702 - val_accuracy: 0.9474\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 267s 855ms/step - loss: 0.1342 - accuracy: 0.9592 - val_loss: 0.1478 - val_accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "resnet_history = model1.fit(train_data_10_percent,\n",
    "                                  epochs=5,\n",
    "                                  steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extraction_layer (  (None, 1001)              3540265   \n",
      " KerasLayer)                                                     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 4)                 4008      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3544273 (13.52 MB)\n",
      "Trainable params: 4008 (15.66 KB)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "hdf5_model_save_path = '/DATASCIENCE/model2.h5'\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model1.save(hdf5_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/06 20:13:29 INFO mlflow.tracking.fluent: Experiment with name 'MLops_Mission_Impossible' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/543761410144953044', creation_time=1704552209305, experiment_id='543761410144953044', last_update_time=1704552209305, lifecycle_stage='active', name='MLops_Mission_Impossible', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tensorflow import MLflowCallback\n",
    "\n",
    "# Set the experiment name\n",
    "experiment_name = \"MLops_Mission_Impossible\"\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/06 21:03:13 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: e:\\datascience\\model3\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: e:\\datascience\\model3\\data\\model\\assets\n",
      "c:\\Users\\HP\\anaconda3\\envs\\MLops\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model with the name \"model3\"\n",
    "mlflow.tensorflow.save_model(model1, \"model3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "312/312 [==============================] - 224s 718ms/step - loss: 0.0730 - accuracy: 0.9798 - val_loss: 0.0984 - val_accuracy: 0.9655\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 225s 722ms/step - loss: 0.0660 - accuracy: 0.9832 - val_loss: 0.1013 - val_accuracy: 0.9655\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 222s 711ms/step - loss: 0.0617 - accuracy: 0.9826 - val_loss: 0.0824 - val_accuracy: 0.9771\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 227s 728ms/step - loss: 0.0555 - accuracy: 0.9856 - val_loss: 0.0852 - val_accuracy: 0.9763\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 330s 1s/step - loss: 0.0512 - accuracy: 0.9872 - val_loss: 0.0819 - val_accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tensorflow import MLflowCallback\n",
    "\n",
    "# Start the MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Log the model parameters\n",
    "    mlflow.log_param(\"epochs\", 5)\n",
    "    mlflow.log_param(\"steps_per_epoch\", len(train_data_10_percent))\n",
    "    # Log other hyperparameters as needed\n",
    "\n",
    "    # Train your model with MLflowCallback\n",
    "    resnet_history = model1.fit(\n",
    "        train_data_10_percent,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=len(train_data_10_percent),\n",
    "        validation_data=test_data,\n",
    "        validation_steps=len(test_data),\n",
    "        callbacks=[MLflowCallback(run)],\n",
    "    )\n",
    "\n",
    "    # Log the final metrics after training\n",
    "    mlflow.log_metrics({\n",
    "        \"final_loss\": resnet_history.history[\"loss\"][-1],\n",
    "        \"final_accuracy\": resnet_history.history[\"accuracy\"][-1],\n",
    "        \"final_val_loss\": resnet_history.history[\"val_loss\"][-1],\n",
    "        \"final_val_accuracy\": resnet_history.history[\"val_accuracy\"][-1],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 602ms/step\n",
      "Predicted label: Cyst\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Function to load the model with custom object scope\n",
    "def load_model_with_custom_objects(model_path):\n",
    "    # Define a custom_objects dictionary to handle the KerasLayer\n",
    "    custom_objects = {'KerasLayer': hub.KerasLayer}\n",
    "    # Load the model with the custom_objects scope\n",
    "    model = load_model(model_path, custom_objects=custom_objects)\n",
    "    return model\n",
    "\n",
    "# Load the trained model with custom object scope\n",
    "model_path = 'model2.h5'\n",
    "model = load_model_with_custom_objects(model_path)\n",
    "\n",
    "# Define IMAGE_SHAPE based on the expected input shape of the model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Cyst', 'Normal', 'Stone', 'Tumor']\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SHAPE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  \n",
    "    return img_array\n",
    "\n",
    "def predict_class(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "    return predicted_class_label\n",
    "\n",
    "# Example image path\n",
    "image_path = 'Cyst- (35).jpg'\n",
    "\n",
    "# Make a prediction\n",
    "predicted_label = predict_class(image_path)\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
