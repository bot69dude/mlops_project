{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'.\n",
      "There are 4 directories and 0 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\test'.\n",
      "There are 0 directories and 742 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\test\\Cyst'.\n",
      "There are 0 directories and 1016 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\test\\Normal'.\n",
      "There are 0 directories and 276 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\test\\Stone'.\n",
      "There are 0 directories and 457 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\test\\Tumor'.\n",
      "There are 4 directories and 0 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\train'.\n",
      "There are 0 directories and 2967 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\train\\Cyst'.\n",
      "There are 0 directories and 4061 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\train\\Normal'.\n",
      "There are 0 directories and 1101 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\train\\Stone'.\n",
      "There are 0 directories and 1826 images in 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\\train\\Tumor'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/train/\"\n",
    "test_dir = \"CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:\n",
      "Found 9955 images belonging to 4 classes.\n",
      "Testing images:\n",
      "Found 2491 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=IMAGE_SHAPE,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               class_mode=\"categorical\")\n",
    "\n",
    "print(\"Testing images:\")\n",
    "test_data = train_datagen.flow_from_directory(test_dir,\n",
    "                                              target_size=IMAGE_SHAPE,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              class_mode=\"categorical\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define IMAGE_SHAPE based on the expected input shape of the model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "def create_model(model_url, num_classes=4):\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                             trainable=False,  # freeze the underlying patterns\n",
    "                                             name='feature_extraction_layer',\n",
    "                                             input_shape=IMAGE_SHAPE + (3,))  # define the input image shape\n",
    "\n",
    "    # Create our own model\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,  # use the feature extraction layer as the base\n",
    "        layers.Dense(num_classes, activation='softmax', name='output_layer')  # create our own output layer\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model1 = create_model(\"https://www.kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow2/variations/tf2-preview-classification/versions/4\", num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "312/312 [==============================] - 385s 1s/step - loss: 0.5252 - accuracy: 0.8097 - val_loss: 0.3248 - val_accuracy: 0.8940\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 221s 707ms/step - loss: 0.2566 - accuracy: 0.9189 - val_loss: 0.2509 - val_accuracy: 0.9057\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 218s 699ms/step - loss: 0.1906 - accuracy: 0.9388 - val_loss: 0.2001 - val_accuracy: 0.9382\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 218s 698ms/step - loss: 0.1561 - accuracy: 0.9499 - val_loss: 0.1669 - val_accuracy: 0.9478\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 220s 706ms/step - loss: 0.1346 - accuracy: 0.9588 - val_loss: 0.1589 - val_accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "resnet_history = model1.fit(train_data_10_percent,\n",
    "                                  epochs=5,\n",
    "                                  steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extraction_layer (  (None, 1001)              3540265   \n",
      " KerasLayer)                                                     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 4)                 4008      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3544273 (13.52 MB)\n",
      "Trainable params: 4008 (15.66 KB)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (32, 224, 224, 3)\n",
      "Labels shape: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "# Add these lines before the fit function\n",
    "for data, labels in train_data_10_percent:\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    break  # Print the shape of the first batch only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup MLflow in Terminal:\n",
    "# Command : \n",
    " mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/12 15:05:37 INFO mlflow.tracking.fluent: Experiment with name 'MLops_Production' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/361568761679039183', creation_time=1705052137993, experiment_id='361568761679039183', last_update_time=1705052137993, lifecycle_stage='active', name='MLops_Production', tags={}>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "experiment_name = \"MLops_Production\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "312/312 [==============================] - 225s 721ms/step - loss: 0.1164 - accuracy: 0.9647 - val_loss: 0.1543 - val_accuracy: 0.9470\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 218s 697ms/step - loss: 0.1032 - accuracy: 0.9695 - val_loss: 0.1277 - val_accuracy: 0.9582\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 221s 708ms/step - loss: 0.0919 - accuracy: 0.9744 - val_loss: 0.1469 - val_accuracy: 0.9502\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 215s 690ms/step - loss: 0.0848 - accuracy: 0.9770 - val_loss: 0.1124 - val_accuracy: 0.9631\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 215s 688ms/step - loss: 0.0768 - accuracy: 0.9796 - val_loss: 0.1075 - val_accuracy: 0.9627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/12 15:23:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpmfvphbqh\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpmfvphbqh\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tensorflow import MLflowCallback\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "\n",
    "# Create and compile your model\n",
    "\n",
    "# Start the MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Log the model parameters\n",
    "    mlflow.log_param(\"epochs\", 5)\n",
    "    mlflow.log_param(\"steps_per_epoch\", len(train_data_10_percent))\n",
    "    # Log other hyperparameters as needed\n",
    "\n",
    "    # Train your model with MLflowCallback\n",
    "    resnet_history = model1.fit(train_data_10_percent,\n",
    "                                  epochs=5,\n",
    "                                  steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data),\n",
    "                                  callbacks=[MLflowCallback(run)]\n",
    "                                  )\n",
    "\n",
    "    # Log the final metrics after training\n",
    "    mlflow.log_metrics({\n",
    "        \"final_loss\": resnet_history.history[\"loss\"][-1],\n",
    "        \"final_accuracy\": resnet_history.history[\"accuracy\"][-1],\n",
    "        \"final_val_loss\": resnet_history.history[\"val_loss\"][-1],\n",
    "        \"final_val_accuracy\": resnet_history.history[\"val_accuracy\"][-1],\n",
    "    })\n",
    "    \n",
    "    mlflow.tensorflow.log_model(model1, \"model\")\n",
    "\n",
    "    mlflow_run_id = run.info.run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/12 15:25:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: e:\\datascience\\model_final_2.0\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: e:\\datascience\\model_final_2.0\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.save_model(model1, \"model_final_2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted label: Normal\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "model2 = mlflow.tensorflow.load_model(\"model_final_2.0\")\n",
    "\n",
    "\n",
    "# Define IMAGE_SHAPE based on the expected input shape of the model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Cyst', 'Normal', 'Stone', 'Tumor']\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SHAPE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  \n",
    "    return img_array\n",
    "\n",
    "def predict_class(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model2.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "    return predicted_class_label\n",
    "\n",
    "# Example image path\n",
    "image_path = 'Normal- (705).jpg'\n",
    "\n",
    "# Make a prediction\n",
    "predicted_label = predict_class(image_path)\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Kidney_CT_Scan\"\n",
    "model_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFlow Run ID:  0831f5273e0a466d8d72f100734db7da\n"
     ]
    }
   ],
   "source": [
    "print(\"MLFlow Run ID: \",mlflow_run_id)\n",
    "logged_model_path = f\"runs:/{mlflow_run_id}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Kidney_CT_Scan'.\n",
      "2024/01/12 15:26:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Kidney_CT_Scan, version 1\n",
      "Created version '1' of model 'Kidney_CT_Scan'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_id=mlflow_run_id) as run:\n",
    "    result = mlflow.register_model(\n",
    "        logged_model_path,\n",
    "        model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_31316\\128635073.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1705053378906, current_stage='Production', description='', last_updated_timestamp=1705053382831, name='Kidney_CT_Scan', run_id='0831f5273e0a466d8d72f100734db7da', run_link='', source='mlflow-artifacts:/361568761679039183/0831f5273e0a466d8d72f100734db7da/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=\"Production\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 880ms/step\n",
      "Predicted label: Normal\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "model2 = mlflow.tensorflow.load_model(\"model_final\")\n",
    "\n",
    "\n",
    "# Define IMAGE_SHAPE based on the expected input shape of the model\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Cyst', 'Normal', 'Stone', 'Tumor']\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SHAPE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0  \n",
    "    return img_array\n",
    "\n",
    "def predict_class(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model2.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "    return predicted_class_label\n",
    "\n",
    "# Example image path\n",
    "image_path = 'Normal- (705).jpg'\n",
    "\n",
    "# Make a prediction\n",
    "predicted_label = predict_class(image_path)\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.tensorflow.load_model(\n",
    "    model_uri=f\"models:/{model_name}/production\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
